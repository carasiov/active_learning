# Baseline (Standard Decoder) for Heteroscedastic Comparison
#
# Purpose: Baseline comparison for heteroscedastic decoder validation
# Configuration identical to heteroscedastic_validation.yaml except:
#   - use_heteroscedastic_decoder: false
#
# This allows direct comparison to measure the value of learned variance.

experiment:
  name: "heteroscedastic_baseline"
  description: "Baseline with standard decoder (no learned variance)"
  output_dir: "use_cases/experiments/results"

model:
  # Architecture (IDENTICAL to heteroscedastic_validation.yaml)
  encoder_type: "dense"
  decoder_type: "dense"
  latent_dim: 16
  hidden_dims: [256, 128, 64]

  # Prior configuration (IDENTICAL)
  prior_type: "mixture"
  num_components: 10
  use_component_aware_decoder: true
  component_embedding_dim: 8

  # Standard decoder (KEY DIFFERENCE)
  use_heteroscedastic_decoder: false
  # sigma_min and sigma_max not used for standard decoder

  # Classifier (IDENTICAL)
  use_tau_classifier: true
  tau_smoothing_alpha: 1.0

  # Loss weights (IDENTICAL)
  reconstruction_loss: "mse"
  recon_weight: 500.0
  kl_weight: 5.0
  kl_c_weight: 0.001
  label_weight: 0.0

  # Regularization (IDENTICAL)
  component_diversity_weight: -0.05
  dirichlet_alpha: 5.0
  dirichlet_weight: 1.0

training:
  # Training configuration (IDENTICAL)
  batch_size: 128
  max_epochs: 50
  learning_rate: 0.001
  patience: 10
  val_split: 0.1
  random_seed: 42

data:
  # Data configuration (IDENTICAL)
  dataset: "MNIST"
  num_labeled: 50
  flatten: false

# Expected comparison results:
# 1. MSE: Heteroscedastic should be similar or better
#    (mean predictions should be as good or better)
# 2. NLL: Cannot directly compare (different likelihood models)
#    - Standard: assumes fixed σ² = 1 implicitly
#    - Heteroscedastic: learns σ²(x) per input
# 3. OOD detection: Heteroscedastic should be better
#    (can combine latent uncertainty with aleatoric uncertainty)
# 4. Calibration: Heteroscedastic should be better
#    (uncertainty estimates should better match actual errors)
