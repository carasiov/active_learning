# Training Hub Redesign

## Overview

Redesign the Training Hub to provide a clean, organized, and contextually-aware training configuration interface. Parameters should be grouped logically, with prior-specific settings shown conditionally based on the model's architecture.

## Design Philosophy

**Core Principles**:
1. **Contextual Intelligence**: Show only relevant parameters for the current model's prior type
2. **Information Hierarchy**: Group parameters by purpose, not alphabetically
3. **Visual Coherence**: Match the overall dashboard design (typography, colors, spacing)
4. **Progressive Disclosure**: Essential parameters visible, advanced in collapsible sections
5. **Semantic Clarity**: Use terminology from conceptual model (channels, responsibilities, Ï„-classifier)

**Visual Language** (from existing app):
- **Primary Color**: #C10A27 (red accent, buttons)
- **Secondary Color**: #45717A (teal, secondary actions)
- **Neutral Dark**: #000000 (headings)
- **Neutral Medium**: #6F6F6F (body text, labels)
- **Neutral Light**: #C6C6C6 (borders)
- **Background**: #ffffff (cards), #f5f5f5 (page), #fafafa (sections)
- **Font**: 'Open Sans', Verdana, sans-serif
- **Monospace**: ui-monospace, monospace (numbers, technical values)

## Layout Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Hub                                                 â”‚
â”‚  Model: experiment-name-123                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Left Panel (40%)    â”‚  â”‚ Right Panel (60%)             â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ Architecture        â”‚  â”‚ Training Progress             â”‚ â”‚
â”‚  â”‚ (read-only summary) â”‚  â”‚ - Loss curves                 â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚ - Metrics                     â”‚ â”‚
â”‚  â”‚ Training Setup      â”‚  â”‚ - Status                      â”‚ â”‚
â”‚  â”‚ - Epochs            â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ - Learning rate     â”‚  â”‚ Recent Runs                   â”‚ â”‚
â”‚  â”‚ - Batch size        â”‚  â”‚ - Last 5 runs                 â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚ - Quick access                â”‚ â”‚
â”‚  â”‚ Loss Weights        â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ - Reconstruction    â”‚  â”‚ Mixture Diagnostics           â”‚ â”‚
â”‚  â”‚ - KL divergence     â”‚  â”‚ (if mixture prior)            â”‚ â”‚
â”‚  â”‚ - Classification    â”‚  â”‚ - Ï€ values chart              â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚ - Component usage             â”‚ â”‚
â”‚  â”‚ [Prior-Specific]    â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ (conditional)       â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ Regularization      â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ (collapsible)       â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚                     â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ [Train Model]       â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ [Stop Training]     â”‚  â”‚                               â”‚ â”‚
â”‚  â”‚ [Configure More...] â”‚  â”‚                               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Left Panel: Configuration Sections

### 1. Architecture Summary (Read-Only, Always Visible)

**Purpose**: Show locked structural parameters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Architecture (fixed at creation)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Prior:       Mixture (10 components)      â”‚
â”‚ Encoder:     Convolutional                â”‚
â”‚ Latent Dim:  2                            â”‚
â”‚ Recon Loss:  BCE (binary)                 â”‚
â”‚                                            â”‚
â”‚ Component-aware decoder: Yes              â”‚
â”‚ Heteroscedastic decoder: No               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Styling**:
- Light gray background (#fafafa)
- Small text (13px)
- Subtle border
- Icon: ğŸ”’ next to title

### 2. Training Setup (Always Visible)

**Purpose**: Core training loop configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Training Setup                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ Epoch Budget              [200 â–¼]         â”‚
â”‚ How many epochs to train                   â”‚
â”‚                                            â”‚
â”‚ Early Stop Patience       [20  â–¼]         â”‚
â”‚ Stop after N epochs without improvement    â”‚
â”‚                                            â”‚
â”‚ Learning Rate             [0.001 â–¼]       â”‚
â”‚ Adam optimizer learning rate               â”‚
â”‚                                            â”‚
â”‚ Batch Size                [128 â–¼]         â”‚
â”‚ Samples per optimization step              â”‚
â”‚                                            â”‚
â”‚ Random Seed               [42  â–¼]         â”‚
â”‚ For reproducibility                        â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `max_epochs` (1-500, default: 200)
- `patience` (1-100, default: 20)
- `learning_rate` (1e-5 to 1e-1, default: 1e-3)
- `batch_size` (32-4096 step 32, default: 128)
- `random_seed` (0-10000, default: 42)

**Validation**:
- Monitor metric selector (if needed): "auto" | "loss" | "classification_loss"

### 3. Loss Weights (Always Visible)

**Purpose**: Balance loss components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Loss Weights                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ Reconstruction            [1.0  â–¼]        â”‚
â”‚ Pixel reconstruction term (BCE scale)      â”‚
â”‚                                            â”‚
â”‚ KL Divergence            [1.0  â–¼]         â”‚
â”‚ Latent regularization (Î² in Î²-VAE)        â”‚
â”‚                                            â”‚
â”‚ Classification           [1.0  â–¼]         â”‚
â”‚ Supervised label loss weight               â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `recon_weight` (0.0-10000, default depends on reconstruction_loss)
  - BCE: default 1.0
  - MSE: default 500.0
- `kl_weight` (0.0-20.0, default: 1.0)
- `label_weight` (0.0-50.0, default: 1.0)

**Helper Text**:
- Show current reconstruction loss type (from architecture)
- Recommend typical weights for that loss type

### 4. Prior-Specific Settings (Conditional)

#### 4A. Standard Prior (No Additional Settings)

**Show**: Simple message
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prior: Standard                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Simple N(0,I) Gaussian prior.              â”‚
â”‚ No additional configuration needed.        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 4B. Mixture Prior Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Mixture Prior Configuration                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ â˜‘ Ï„-Classifier                            â”‚
â”‚ Use latent-only classification via rÃ—Ï„     â”‚
â”‚                                            â”‚
â”‚ Ï„ Smoothing (Î±â‚€)         [1.0  â–¼]        â”‚
â”‚ Laplace smoothing for unseen câ†’y pairs    â”‚
â”‚                                            â”‚
â”‚ Component KL Weight      [1.0  â–¼]         â”‚
â”‚ Weight on KL(q(c|x) || Ï€)                 â”‚
â”‚                                            â”‚
â”‚ KL Anneal Epochs         [0    â–¼]         â”‚
â”‚ Ramp component KL from 0 over N epochs    â”‚
â”‚                                            â”‚
â”‚ â˜‘ Learnable Ï€                             â”‚
â”‚ Allow mixture weights to adapt             â”‚
â”‚                                            â”‚
â”‚ Usage Entropy Weight     [-0.1 â–¼]         â”‚
â”‚ Entropy H[pÌ‚_c]: negative = reward diversity â”‚
â”‚                                            â”‚
â”‚ â”€â”€â”€ Advanced Mixture Options â–¼ â”€â”€â”€        â”‚
â”‚                                            â”‚
â”‚ Dirichlet Î± (Ï€ prior)    [blank]          â”‚
â”‚ MAP regularization strength (optional)     â”‚
â”‚                                            â”‚
â”‚ Dirichlet Weight         [1.0  â–¼]         â”‚
â”‚ Scaling for Dirichlet penalty              â”‚
â”‚                                            â”‚
â”‚ Top-M Gating             [0    â–¼]         â”‚
â”‚ Reconstruct with top M components (0=all)  â”‚
â”‚                                            â”‚
â”‚ Soft Embedding Warmup    [0    â–¼]         â”‚
â”‚ Use soft embeddings for first N epochs    â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `use_tau_classifier` (boolean, default: True)
- `tau_smoothing_alpha` (>0, default: 1.0)
- `kl_c_weight` (0.0-10.0, default: 1.0)
- `kl_c_anneal_epochs` (0-500, default: 0)
- `learnable_pi` (boolean, default: True)
- `component_diversity_weight` (-10.0 to 10.0, default: -0.1)
  - Label: "Usage Entropy Weight"
  - Description: "Entropy H[pÌ‚_c]: negative = reward diversity"
- **Advanced** (collapsible):
  - `dirichlet_alpha` (0.1-10.0 or blank, default: None)
  - `dirichlet_weight` (0.0-10.0, default: 1.0)
  - `top_m_gating` (0-num_components, default: 0)
  - `soft_embedding_warmup_epochs` (0-500, default: 0)

**Semantic Notes**:
- Use terminology from conceptual model: "channels" = "components", "responsibilities" = r, "Ï„-classifier"
- Usage entropy: H[pÌ‚_c] where pÌ‚_c is empirical component usage. Negative weight = entropy reward (encourage diverse usage)
- Show component count from architecture summary

#### 4C. VampPrior Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VampPrior Configuration                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ â˜‘ Ï„-Classifier                            â”‚
â”‚ Use latent-only classification via rÃ—Ï„     â”‚
â”‚                                            â”‚
â”‚ Ï„ Smoothing (Î±â‚€)         [1.0  â–¼]        â”‚
â”‚ Laplace smoothing for unseen câ†’y pairs    â”‚
â”‚                                            â”‚
â”‚ Component KL Weight      [1.0  â–¼]         â”‚
â”‚ Weight on KL(q(c|x) || Ï€)                 â”‚
â”‚                                            â”‚
â”‚ KL Anneal Epochs         [0    â–¼]         â”‚
â”‚ Ramp component KL from 0 over N epochs    â”‚
â”‚                                            â”‚
â”‚ Usage Entropy Weight     [-0.1 â–¼]         â”‚
â”‚ Entropy H[pÌ‚_c]: negative = reward diversity â”‚
â”‚                                            â”‚
â”‚ â”€â”€â”€ VampPrior-Specific â–¼ â”€â”€â”€              â”‚
â”‚                                            â”‚
â”‚ KL Samples (MC)          [1    â–¼]         â”‚
â”‚ Monte Carlo samples for KL estimation      â”‚
â”‚                                            â”‚
â”‚ Pseudo-Input LR Scale    [0.1  â–¼]         â”‚
â”‚ Learning rate multiplier for u_k           â”‚
â”‚                                            â”‚
â”‚ Note: Pseudo-inputs initialized at model   â”‚
â”‚ creation. Î  is uniform for VampPrior.     â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `use_tau_classifier` (boolean, default: True)
- `tau_smoothing_alpha` (>0, default: 1.0)
- `kl_c_weight` (0.0-10.0, default: 1.0)
- `kl_c_anneal_epochs` (0-500, default: 0)
- `component_diversity_weight` (-10.0 to 10.0, default: -0.1)
  - Label: "Usage Entropy Weight"
  - Description: "Entropy H[pÌ‚_c]: negative = reward diversity"
- **VampPrior-Specific**:
  - `vamp_num_samples_kl` (1-10, default: 1)
  - `vamp_pseudo_lr_scale` (0.01-1.0, default: 0.1)

**Info Box**:
- Note that Ï€ is uniform (not learnable) for VampPrior
- Pseudo-inputs are initialized at creation time using method specified in architecture

#### 4D. Geometric MoG Settings

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Geometric MoG Configuration                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ â˜‘ Ï„-Classifier                            â”‚
â”‚ Use latent-only classification via rÃ—Ï„     â”‚
â”‚                                            â”‚
â”‚ Ï„ Smoothing (Î±â‚€)         [1.0  â–¼]        â”‚
â”‚ Laplace smoothing for unseen câ†’y pairs    â”‚
â”‚                                            â”‚
â”‚ Component KL Weight      [1.0  â–¼]         â”‚
â”‚ Weight on KL(q(c|x) || Ï€)                 â”‚
â”‚                                            â”‚
â”‚ â˜‘ Learnable Ï€                             â”‚
â”‚ Allow mixture weights to adapt             â”‚
â”‚                                            â”‚
â”‚ Usage Entropy Weight     [-0.1 â–¼]         â”‚
â”‚ Entropy H[pÌ‚_c]: negative = reward diversity â”‚
â”‚                                            â”‚
â”‚ Note: Components arranged geometrically   â”‚
â”‚ (circle/grid) with fixed spacing. See     â”‚
â”‚ architecture summary for arrangement.      â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `use_tau_classifier` (boolean, default: True)
- `tau_smoothing_alpha` (>0, default: 1.0)
- `kl_c_weight` (0.0-10.0, default: 1.0)
- `learnable_pi` (boolean, default: True)
- `component_diversity_weight` (-10.0 to 10.0, default: -0.1)
  - Label: "Usage Entropy Weight"
  - Description: "Entropy H[pÌ‚_c]: negative = reward diversity"

**Info Note**:
- Factual note about geometric arrangement being structural (locked at creation)

### 5. Regularization (Collapsible, Always Available)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Regularization â–¼                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                            â”‚
â”‚ Weight Decay             [0.0001 â–¼]       â”‚
â”‚ L2 regularization (AdamW)                  â”‚
â”‚                                            â”‚
â”‚ Gradient Clip Norm       [1.0  â–¼]         â”‚
â”‚ Clip gradients by global norm (0=off)     â”‚
â”‚                                            â”‚
â”‚ Classifier Dropout       [0.2  â–¼]         â”‚
â”‚ Dropout rate in classifier head            â”‚
â”‚                                            â”‚
â”‚ â”€â”€â”€ Heteroscedastic Decoder â”€â”€â”€           â”‚
â”‚ (only if enabled in architecture)          â”‚
â”‚                                            â”‚
â”‚ Ïƒ Min                    [0.05 â–¼]         â”‚
â”‚ Minimum decoder variance                   â”‚
â”‚                                            â”‚
â”‚ Ïƒ Max                    [0.5  â–¼]         â”‚
â”‚ Maximum decoder variance                   â”‚
â”‚                                            â”‚
â”‚ â”€â”€â”€ Contrastive Learning â”€â”€â”€              â”‚
â”‚                                            â”‚
â”‚ â˜ Enable Contrastive                      â”‚
â”‚ Add supervised contrastive loss            â”‚
â”‚                                            â”‚
â”‚ Contrastive Weight       [0.0  â–¼]         â”‚
â”‚ Scaling for contrastive term               â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Fields**:
- `weight_decay` (0.0-0.1, default: 1e-4)
- `grad_clip_norm` (0.0-100.0, default: 1.0, 0=disabled)
- `dropout_rate` (0.0-0.8, default: 0.2)
- **Heteroscedastic** (if architecture has it):
  - `sigma_min` (1e-5 to 5.0, default: 0.05)
  - `sigma_max` (0.01-10.0, default: 0.5)
- **Contrastive**:
  - `use_contrastive` (boolean, default: False)
  - `contrastive_weight` (0.0-50.0, default: 0.0)

### 6. Action Buttons (Always Visible)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                            â”‚
â”‚ [  Train Model for N Epochs  ]            â”‚
â”‚ Start/resume training                      â”‚
â”‚                                            â”‚
â”‚ [  Stop Training  ]                        â”‚
â”‚ Gracefully halt (if running)               â”‚
â”‚                                            â”‚
â”‚ [  Full Configuration...  ]               â”‚
â”‚ Open detailed config editor                â”‚
â”‚                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Buttons**:
- **Train**: Primary red (#C10A27), full width, shows "Training..." when active
- **Stop**: Secondary gray, full width, disabled when idle
- **Full Config**: Outline button, links to `/model/{id}/configure-training`

## Implementation Strategy

**Note on Mockup Values**: The values shown in mockups (e.g., epochs=200, kl_weight=1.0) are recommendations for typical mixture model workflows. The actual implementation should:
1. Pull current values from `ModelState.config` (the source of truth)
2. Display the model's actual configured values, not hardcoded defaults
3. Some config defaults (e.g., `recon_weight=500` for MSE) will differ from what's shown in mockups (which assume BCE)

### Phase 1: Architecture Summary & Parameter Grouping

1. Add read-only architecture display at top of left panel
2. Group existing parameters into logical sections (Training Setup, Loss Weights)
3. Update styling to match design system

### Phase 2: Conditional Prior Sections

1. Implement prior type detection from `ModelState.config.prior_type`
2. Create component for each prior type's settings
3. Add conditional rendering logic
4. Test with each prior type

### Phase 3: Advanced Options & Polish

1. Implement collapsible sections (Regularization, Advanced Mixture)
2. Add helper text and tooltips
3. Validate parameter interdependencies
4. Polish spacing, typography, colors

### Phase 4: Full Configuration Link

1. Keep existing `/configure-training` page for power users
2. Add "Full Configuration..." button linking to it
3. Ensure both interfaces sync state properly

## Parameter Organization by Purpose

### Essential (Always Visible)
- Training loop: epochs, patience, learning rate, batch size
- Loss balance: recon_weight, kl_weight, label_weight

### Prior-Specific (Conditional)
- **Mixture**: Ï„-classifier, component KL, usage entropy, learnable Ï€
- **VampPrior**: Ï„-classifier, component KL, usage entropy, pseudo-input LR
- **Geometric**: Ï„-classifier, component KL, usage entropy, learnable Ï€
- **Standard**: (none - just a note)

### Advanced (Collapsible)
- Regularization: weight decay, grad clip, dropout
- Heteroscedastic: sigma bounds (if enabled)
- Contrastive: enable + weight
- Mixture advanced: Dirichlet prior, gating, warmup

## Semantic Alignment with Conceptual Model

**Terminology Mapping**:
- âœ… "Component" or "Channel" (not "cluster" or "mode")
- âœ… "Responsibilities" r (not "assignments")
- âœ… "Ï„-Classifier" (channelâ†’label map)
- âœ… "Usage Entropy" H[pÌ‚_c] (not "diversity")
- âœ… "Ï€" (mixture weights)
- âœ… "Latent-only classification" (via rÃ—Ï„)

**Conceptual Guidance**:
- Explain that Ï„-classifier uses responsibilities to classify
- Note that usage entropy H[pÌ‚_c]: negative weight = entropy reward (encourage diverse component usage)
- Clarify that component-aware decoder was set at creation
- Link parameters to objectives (KL on c, entropy on usage)

## Visual Design Spec

### Typography
```css
{
  /* Section headings */
  fontSize: "17px",
  fontWeight: "700",
  color: "#000000",
  fontFamily: "'Open Sans', Verdana, sans-serif",

  /* Parameter labels */
  fontSize: "14px",
  fontWeight: "600",
  color: "#6F6F6F",
  fontFamily: "'Open Sans', Verdana, sans-serif",

  /* Helper text */
  fontSize: "12px",
  fontWeight: "400",
  color: "#6F6F6F",
  fontFamily: "'Open Sans', Verdana, sans-serif",

  /* Numeric values */
  fontSize: "14px",
  fontFamily: "ui-monospace, monospace",
}
```

### Colors
```css
{
  /* Primary action */
  backgroundColor: "#C10A27",
  color: "#ffffff",

  /* Secondary action */
  backgroundColor: "#45717A",
  color: "#ffffff",

  /* Card backgrounds */
  backgroundColor: "#ffffff",
  border: "1px solid #C6C6C6",

  /* Page background */
  backgroundColor: "#f5f5f5",

  /* Input fields */
  border: "1px solid #C6C6C6",
  borderRadius: "6px",

  /* Architecture summary (locked) */
  backgroundColor: "#fafafa",
  border: "1px solid #E6E6E6",
}
```

### Spacing
```css
{
  /* Section margins */
  marginBottom: "24px",

  /* Card padding */
  padding: "24px",

  /* Input groups */
  marginBottom: "16px",

  /* Label-input gap */
  marginBottom: "6px",

  /* Input padding */
  padding: "10px 12px",
}
```

## Migration Notes

### For Users
- Training Hub now shows only relevant parameters for your model's prior type
- Structural parameters (prior, encoder, latent dim) are read-only - shown at top
- Full configuration editor still available via "Full Configuration..." button
- All settings persist between training runs

### For Developers
- Prior-specific sections use conditional rendering based on `config.prior_type`
- Architecture summary pulls from locked structural parameters
- Helper text uses terminology from conceptual model
- Visual design matches homepage and overall app style
