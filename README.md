# Active Learning â€“ Semi-Supervised VAE (JAX/Flax)

> Modular semi-supervised variational autoencoder for learning from predominantly unlabeled data.  
> JAX/Flax implementation.

---

## What is this?

### Current Implementation Status

The repository provides:
- **Semi-supervised VAE** (JAX/Flax) with standard and Priors v1 mixture prior
  - Learnable mixture weights Ï€ (via `prior/pi_logits`, no weight decay)
  - Conditional decoder via concatenation `[z; e_c]` and exact expected reconstruction over components
- **Losses (Priors v1)**
  - `KL_z(q(z|x)||N(0,I))` and `KL_c(q(c|x)||Ï€)` with separate weights
  - Optional Dirichlet MAP on Ï€ (`dirichlet_alpha`, `dirichlet_weight`)
  - Optional usage sparsity on empirical component usage
  - Reported auxiliary metric `loss_no_global_priors` (recon + KL only)
- **Training infrastructure** for incremental/interactive runs with curriculum support
- **Experiment scripts** to compare configurations and generate reports
  - Reports include loss curves, latent plots, reconstruction grids, and mixture diagnostics (Ï€, usage, entropies)
- **Dashboard scaffold** (`use_cases/dashboard/`) for interactive labeling interface

## Project Structure

```
active_learning_showcase/
â”‚
â”œâ”€â”€ src/ssvae/                   # ğŸ§  Core Model (JAX/Flax)
â”‚   â”œâ”€â”€ models.py                #    SSVAE class (public API)
â”‚   â”œâ”€â”€ config.py                #    SSVAEConfig (25+ hyperparameters)
â”‚   â””â”€â”€ components/              #    Encoder, decoder, classifier (factory pattern)
â”‚
â”œâ”€â”€ src/training/                # ğŸ”„ Training Infrastructure
â”‚   â”œâ”€â”€ trainer.py               #    Training loop with early stopping
â”‚   â”œâ”€â”€ losses.py                #    Loss functions (reconstruction, KL, classification)
â”‚   â””â”€â”€ interactive_trainer.py  #    Incremental training for active learning
â”‚
â”œâ”€â”€ src/callbacks/               # ğŸ“Š Training Observability
â”‚   â”œâ”€â”€ logging.py               #    Console & CSV logging
â”‚   â””â”€â”€ plotting.py              #    Loss curve visualization
â”‚
â”œâ”€â”€ scripts/                     # ğŸ”¬ Experimentation Tools (Current Focus)
â”‚   â”œâ”€â”€ compare_models.py        #    Compare model configurations
â”‚   â””â”€â”€ comparison_utils.py      #    Visualization & reporting utilities
â”‚
â”œâ”€â”€ use_cases/dashboard/         # ğŸ›ï¸ Interactive Interface (Future Focus)
â”‚   â”œâ”€â”€ app.py                   #    Web-based active learning interface
â”‚   â”œâ”€â”€ core/                    #    State management & commands
â”‚   â”œâ”€â”€ pages/                   #    Dashboard UI pages
â”‚   â””â”€â”€ docs/                    #    Dashboard-specific documentation
â”‚
â”œâ”€â”€ configs/comparisons/         # âš™ï¸ Experiment Configurations
â”‚   â””â”€â”€ *.yaml                   #    YAML configs for model comparisons
â”‚
â”œâ”€â”€ data/mnist/                  # ğŸ“¦ Dataset
â”‚   â””â”€â”€ labels.csv               #    Shared label format (Serial, label)
â”‚
â”œâ”€â”€ artifacts/                   # ğŸ’¾ Outputs
â”‚   â”œâ”€â”€ comparisons/             #    Experiment results (plots, metrics, reports)
â”‚   â”œâ”€â”€ checkpoints/             #    Model weights
â”‚   â””â”€â”€ models/                  #    Dashboard model state
â”‚
â””â”€â”€ docs/                        # ğŸ“– Documentation
    â””â”€â”€...
```

### Component Relationships

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SSVAE Model Core                       â”‚
â”‚  (src/ssvae/ + src/training/ + src/callbacks/)              â”‚
â”‚                                                              â”‚
â”‚  â€¢ Configuration-driven architecture                         â”‚
â”‚  â€¢ Factory pattern for components                            â”‚
â”‚  â€¢ Pure functional training loop                             â”‚
â”‚  â€¢ Callback-based observability                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                              â”‚
               â”‚                              â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Comparison Tool â”‚          â”‚     Dashboard      â”‚
     â”‚  (scripts/)      â”‚          â”‚  (use_cases/)      â”‚
     â”‚                  â”‚          â”‚                    â”‚
     â”‚  Current primary â”‚          â”‚  Future primary    â”‚
     â”‚  workflow for    â”‚          â”‚  interface once    â”‚
     â”‚  experimentation â”‚          â”‚  features stable   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Current Reality:** Experimentation happens via `scripts/compare_models.py` for rapid iteration and validation.

**Target State:** Dashboard becomes the primary interface for interactive active learning once model features stabilize.

---


## Quick Start

Get your first results in under 3 minutes:

```bash
# 1. Install dependencies (one-time setup)
poetry install

# 2. Run a model comparison
poetry run python scripts/compare_models.py --models standard mixture_k10 --epochs 10
```

**Output:** `artifacts/comparisons/20241031_143022/` with loss curves, latent visualizations, metrics, and checkpoints.

**Next steps:** [Getting Started Guide](docs/GETTING_STARTED.md) for detailed setup and verification.

---

## Usage

All usage patterns are documented in the [**Usage Guide**](docs/USAGE.md):

- **[Comparison Tool](docs/USAGE.md#comparison-tool)** - Command-line experimentation (current primary workflow)
- **[Interactive Dashboard](docs/USAGE.md#interactive-dashboard)** - Web interface for active learning  
- **[Python API](docs/USAGE.md#python-api)** - Programmatic access for custom integration
- **[Legacy Tools](docs/USAGE.md#legacy-tools)** - Single-model CLI scripts

**Quick example:**

```bash
# Compare two models
poetry run python scripts/compare_models.py --models standard mixture_k10 --epochs 10
```

See the [Usage Guide](docs/USAGE.md) for detailed examples, workflows, and troubleshooting.

---

**Context & Philosophy:**

- ğŸ“– [**Context & Motivation**](docs/CONTEXT.md) - Why this architecture? What's the target application? Why MNIST first?

**Specialized Guides:**

- ğŸ³ [GPU Setup & Troubleshooting](.devcontainer/README.md) - Devcontainer, CUDA, device selection
- ğŸ”¬ [Comparison Tool Details](configs/comparisons/README.md) - YAML configs, options, troubleshooting  
- ğŸ›ï¸ [Dashboard Overview](use_cases/dashboard/README.md) - Features, routing, development
- ğŸ¤– [Dashboard Extensions](use_cases/dashboard/docs/AGENT_GUIDE.md) - Adding commands, UI, callbacks
- ğŸ”§ [Dashboard Internals](use_cases/dashboard/docs/DEVELOPER_GUIDE.md) - Architecture, debugging, state

