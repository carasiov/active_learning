{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised VAE Showcase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how the refactored SSVAE learns useful structure from mostly unlabeled data in three stages: (1) random initialization, (2) unsupervised VAE training, and (3) semi-supervised fine-tuning with only 50 labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Ensure project root is on sys.path\n",
    "ROOT = Path.cwd()\n",
    "while ROOT != ROOT.parent and not (ROOT / 'pyproject.toml').exists():\n",
    "    ROOT = ROOT.parent\n",
    "if (ROOT / 'pyproject.toml').exists() and str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "from configs.base import SSVAEConfig\n",
    "from ssvae import SSVAE\n",
    "from training.interactive_trainer import InteractiveTrainer\n",
    "\n",
    "np.random.seed(0)\n",
    "ARTIFACT_DIR = ROOT / 'artifacts' / 'showcase'\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_STAGE2 = ARTIFACT_DIR / 'stage2_unsupervised.ckpt'\n",
    "CHECKPOINT_STAGE3 = ARTIFACT_DIR / 'stage3_semi_supervised.ckpt'\n",
    "plt.rcParams.update({'figure.figsize': (8, 6), 'axes.grid': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_with_labels(z, labels, title, path=None, cmap_name=\"tab10\"):\n",
    "    z = np.asarray(z)\n",
    "    labels = np.asarray(labels)\n",
    "    cmap = plt.cm.get_cmap(cmap_name, 10)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(z[:, 0], z[:, 1], c=labels, cmap=cmap, s=8, alpha=0.6, edgecolors='none')\n",
    "    ax.set_xlabel(\"Latent dim 1\")\n",
    "    ax.set_ylabel(\"Latent dim 2\")\n",
    "    ax.set_title(title)\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=cmap(i), markersize=6, label=str(i))\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, title=\"Digit\", loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    fig.tight_layout()\n",
    "    if path is not None:\n",
    "        fig.savefig(path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n\n",
    "def plot_latent_continuous(z, values, title, path=None, cmap_name=\"viridis\"):\n",
    "    z = np.asarray(z)\n",
    "    values = np.asarray(values)\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    scatter = ax.scatter(z[:, 0], z[:, 1], c=values, cmap=cmap_name, s=8, alpha=0.6, edgecolors='none')\n",
    "    ax.set_xlabel(\"Latent dim 1\")\n",
    "    ax.set_ylabel(\"Latent dim 2\")\n",
    "    ax.set_title(title)\n",
    "    cbar = fig.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(\"Value\")\n",
    "    fig.tight_layout()\n",
    "    if path is not None:\n",
    "        fig.savefig(path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n\n",
    "def show_reconstructions(inputs, reconstructions, count=8, title=\"Reconstructions\", path=None, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = rng.choice(inputs.shape[0], size=count, replace=False)\n",
    "    fig, axes = plt.subplots(2, count, figsize=(1.6 * count, 3.2))\n",
    "    for i, index in enumerate(idx):\n",
    "        axes[0, i].imshow(inputs[index], cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(reconstructions[index], cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    axes[1, 0].set_ylabel(\"Recon\")\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    if path is not None:\n",
    "        fig.savefig(path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fetching MNIST (this may download once)...\")\n",
    "X_all, y_all = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "X_all = X_all.astype(np.float32)\n",
    "y_all = y_all.astype(np.int32)\n\n",
    "TRAIN_SIZE = 10000\n",
    "TEST_SIZE = 2000\n",
    "x_train_raw = X_all[:TRAIN_SIZE]\n",
    "y_train = y_all[:TRAIN_SIZE]\n",
    "x_test_raw = X_all[60000:60000 + TEST_SIZE]\n",
    "y_test = y_all[60000:60000 + TEST_SIZE]\n\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_raw)\n",
    "x_test_scaled = scaler.transform(x_test_raw)\n\n",
    "x_train_images = x_train_scaled.reshape(-1, 28, 28)\n",
    "x_test_images = x_test_scaled.reshape(-1, 28, 28)\n\n",
    "def binarize_images(images, threshold=0.5):\n",
    "    return np.where(images > threshold, 1.0, 0.0).astype(np.float32)\n\n",
    "x_train = binarize_images(x_train_images)\n",
    "x_test = binarize_images(x_test_images)\n\n",
    "labels_all_nan = np.full(x_train.shape[0], np.nan, dtype=np.float32)\n",
    "print(f'Train set: {x_train.shape}, Test set: {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stage 1 \u2013 Untrained Model\n",
    "Random weights yield no meaningful structure in the latent space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SSVAEConfig(max_epochs=60, patience=10, batch_size=1024)\n",
    "stage1_model = SSVAE(input_dim=(28, 28), config=config)\n",
    "stage1_latent, stage1_recon, stage1_pred, stage1_certainty = stage1_model.predict(x_train)\n",
    "plot_latent_with_labels(stage1_latent, y_train, \"Stage 1: Untrained Model (Random Initialization)\", path=ARTIFACT_DIR / \"stage1_latent.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Stage 2 \u2013 Unsupervised Training\n",
    "Train the VAE with no labels to uncover structure from reconstruction alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_model = SSVAE(input_dim=(28, 28), config=config)\n",
    "unsupervised_labels = np.full(x_train.shape[0], np.nan, dtype=np.float32)\n",
    "start = time.time()\n",
    "history_stage2 = stage2_model.fit(x_train, unsupervised_labels, weights_path=str(CHECKPOINT_STAGE2))\n",
    "stage2_elapsed = time.time() - start\n",
    "stage2_recon_loss = history_stage2['reconstruction_loss'][-1]\n",
    "print(f'Unsupervised training time: {stage2_elapsed / 60:.2f} minutes')\n",
    "print(f'Final reconstruction loss: {stage2_recon_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2_latent, stage2_recon, _, _ = stage2_model.predict(x_train)\n",
    "plot_latent_with_labels(stage2_latent, y_train, \"Stage 2: After Unsupervised Training (No Labels Used)\", path=ARTIFACT_DIR / \"stage2_latent.png\")\n",
    "show_reconstructions(x_train, stage2_recon, title=\"Reconstructions After Unsupervised Training\", path=ARTIFACT_DIR / \"stage2_recon.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stage 3 \u2013 Semi-Supervised Fine-Tuning (50 Labels)\n",
    "Select 50 labels (5 per class) and continue training with the interactive trainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "labels_semi = np.full(x_train.shape[0], np.nan, dtype=np.float32)\n",
    "labeled_indices = []\n",
    "for digit in range(10):\n",
    "    digit_idx = np.where(y_train == digit)[0]\n",
    "    chosen = rng.choice(digit_idx, size=5, replace=False)\n",
    "    labeled_indices.extend(chosen)\n",
    "labels_semi[labeled_indices] = y_train[labeled_indices].astype(np.float32)\n",
    "labeled_fraction = len(labeled_indices) / x_train.shape[0]\n",
    "print(f'Number of labeled samples: {len(labeled_indices)} ({labeled_fraction * 100:.2f}% of training data)')\n\n",
    "interactive_trainer = InteractiveTrainer(stage2_model)\n",
    "start = time.time()\n",
    "history_stage3 = interactive_trainer.train_epochs(\n",
    "    num_epochs=15,\n",
    "    data=x_train,\n",
    "    labels=labels_semi,\n",
    "    weights_path=str(CHECKPOINT_STAGE3),\n",
    "    patience=5,\n",
    ")\n",
    "stage3_elapsed = time.time() - start\n",
    "print(f'Semi-supervised fine-tuning time: {stage3_elapsed:.1f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage3_latent, _, stage3_pred, stage3_certainty = stage2_model.predict(x_train)\n",
    "_, _, stage3_pred_test, _ = stage2_model.predict(x_test)\n",
    "labeled_accuracy = np.mean(stage3_pred[labeled_indices] == y_train[labeled_indices])\n",
    "train_accuracy = np.mean(stage3_pred == y_train)\n",
    "test_accuracy = np.mean(stage3_pred_test == y_test)\n",
    "print(f'Accuracy on labeled subset: {labeled_accuracy * 100:.2f}%')\n",
    "print(f'Accuracy on full train set: {train_accuracy * 100:.2f}%')\n",
    "print(f'Accuracy on held-out test set: {test_accuracy * 100:.2f}%')\n",
    "plot_latent_with_labels(stage3_latent, y_train, \"Stage 3: After Semi-Supervised Training (50 Labels)\", path=ARTIFACT_DIR / \"stage3_latent.png\")\n",
    "plot_latent_with_labels(stage3_latent, stage3_pred, \"Predictions on Unlabeled Data\", path=ARTIFACT_DIR / \"stage3_predictions.png\")\n",
    "plot_latent_continuous(stage3_latent, stage3_certainty, \"Prediction Certainty\", path=ARTIFACT_DIR / \"stage3_certainty.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_path = ARTIFACT_DIR / \"comparison.png\"\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharex=True, sharey=True)\n",
    "titles = [\n",
    "    \"Stage 1: Random\",\n",
    "    \"Stage 2: Unsupervised\",\n",
    "    \"Stage 3: Semi-Supervised\",\n",
    "]\n",
    "latent_sets = [stage1_latent, stage2_latent, stage3_latent]\n",
    "for ax, latent, title in zip(axes, latent_sets, titles):\n",
    "    scatter = ax.scatter(latent[:, 0], latent[:, 1], c=y_train, cmap=plt.cm.get_cmap('tab10', 10), s=8, alpha=0.6, edgecolors='none')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Latent dim 1')\n",
    "axes[0].set_ylabel('Latent dim 2')\n",
    "legend_handles = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor=plt.cm.get_cmap('tab10', 10)(i), markersize=6, label=str(i))\n",
    "    for i in range(10)\n",
    "]\n",
    "axes[-1].legend(handles=legend_handles, title='Digit', loc='upper right', bbox_to_anchor=(1.25, 1.0))\n",
    "fig.suptitle('Semi-Supervised Learning Journey: From Random to Structured Classification', fontsize=16)\n",
    "fig.tight_layout()\n",
    "fig.savefig(comparison_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Summary ---')\n",
    "print(f'Train samples used: {x_train.shape[0]} (labels provided for {len(labeled_indices)})')\n",
    "print(f'Fraction labeled: {labeled_fraction * 100:.2f}%')\n",
    "print(f'Unsupervised reconstruction loss: {stage2_recon_loss:.4f}')\n",
    "print(f'Train accuracy after semi-supervised fine-tuning: {train_accuracy * 100:.2f}%')\n",
    "print(f'Test accuracy after semi-supervised fine-tuning: {test_accuracy * 100:.2f}%')\n",
    "print(f'Artifacts saved to: {ARTIFACT_DIR.resolve()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}