# ============================================================================
# Ablation: Strong KL_c + high Dirichlet to keep components uniform (5k / 50 labels)
# ============================================================================

experiment:
  name: "mixture_ablation_uniform_push"
  description: "Increase KL_c and Dirichlet alpha to discourage component collapse"
  tags: ["ablation", "parsimony", "klc-strong"]

data:
  num_samples: 5000
  num_labeled: 50
  seed: 42

model:
  encoder_type: "dense"
  decoder_type: "dense"
  classifier_type: "dense"
  latent_dim: 2
  hidden_dims: [256, 128, 64]

  reconstruction_loss: "bce"
  recon_weight: 1.0
  kl_weight: 0.50
  label_weight: 1.0

  prior_type: "mixture"
  num_components: 10
  kl_c_weight: 0.005          # 10x stronger KL_c
  kl_c_anneal_epochs: 0

  dirichlet_alpha: 5.0        # Encourage uniform Ï€
  dirichlet_weight: 1.0
  usage_sparsity_weight: 0.0  # Remove sparsity penalty for this ablation

  mixture_history_log_every: 1

  learning_rate: 0.001
  batch_size: 128
  max_epochs: 100
  patience: 30
  val_split: 0.1
  random_seed: 42

  grad_clip_norm: 1.0
  weight_decay: 0.0001
  dropout_rate: 0.2

  monitor_metric: "loss"
