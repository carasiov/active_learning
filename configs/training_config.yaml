# ============================================================================
# SSVAE Training Configuration - Complete Reference
# ============================================================================
# All hyperparameters in one place under models section.
# No inheritance, no merging - just specify everything directly.
#
# Usage:
#   python scripts/compare_models.py --config configs/training_config.yaml
# ============================================================================

description: "Complete SSVAE training configuration"

# ============================================================================
# DATA CONFIGURATION
# ============================================================================
data:
  num_samples: 5000      # Total training samples (max: 60000 for MNIST)
  num_labeled: 50        # Labeled samples for semi-supervised learning
  epochs: 30             # Training epochs
  seed: 42               # Random seed for reproducibility

# ============================================================================
# MODEL CONFIGURATION
# ============================================================================
# All SSVAEConfig hyperparameters specified directly.
# Add more models here to compare multiple configurations.

models:
  MyModel:
    # ---- Architecture ----
    encoder_type: "dense"           # "dense" | "conv"
    decoder_type: "dense"           # "dense" | "conv"
    classifier_type: "dense"        # "dense" (only option)
    latent_dim: 2                   # Latent space dimensionality
    hidden_dims: [256, 128, 64]     # Hidden layer sizes (dense networks)
    input_hw: null                  # Optional [height, width] override
    
    # ---- Loss Configuration ----
    reconstruction_loss: "mse"      # "mse" | "bce"
                                    # mse: natural images (weight ~500)
                                    # bce: binary images (weight ~1.0)
    recon_weight: 500.0             # Reconstruction loss weight
    kl_weight: 5.0                  # KL divergence weight
    label_weight: 0.0               # Classification loss weight (unused)
    
    # ---- Prior Configuration ----
    prior_type: "standard"          # "standard" | "mixture"
    num_components: 10              # Mixture components (mixture prior only)
    kl_c_weight: 1.0                # KL(q(c|x)||π) weight (mixture prior only)
    dirichlet_alpha: null           # Optional Dirichlet MAP strength on π
    dirichlet_weight: 1.0           # Scaling for Dirichlet penalty
    usage_sparsity_weight: 0.0      # Encourage sparse component usage
    kl_c_anneal_epochs: 0           # Linear warm-up for kl_c_weight (0 = off)
    
    # ------------------------------------------------------------------------
    # KL-related parameters and prior type behavior:
    #
    # - If prior_type: "standard", only kl_weight is used for KL regularization.
    #   All mixture-specific parameters (kl_c_weight, dirichlet_*, usage_sparsity_weight)
    #   are ignored.
    #
    # - If prior_type: "mixture", kl_weight (for latent), kl_c_weight (for component assignment),
    #   dirichlet_alpha/dirichlet_weight (for mixture weights regularization), and
    #   usage_sparsity_weight (for component usage) are all active and additive in the loss.
    #
    # - Unused parameters for the selected prior are ignored (effectively zeroed out in the loss).
    #
    # Example:
    #   prior_type: "standard"   # Only kl_weight is used
    #   prior_type: "mixture"    # All KL-related terms above are active
    #
    # This ensures experiments are reproducible and interpretable. Adjust only the parameters
    # relevant to your chosen prior type for clarity and correctness.
    # ------------------------------------------------------------------------
    



    # ---- Optimizer & Training ----
    learning_rate: 0.001            # Adam learning rate
    batch_size: 128                 # Training batch size
    max_epochs: 300                 # Maximum epochs
    patience: 50                    # Early stopping patience (epochs)
    val_split: 0.1                  # Validation fraction (0.0-1.0)
    random_seed: 42                 # Initialization seed
    
    # ---- Regularization ----
    grad_clip_norm: 1.0             # Gradient clipping (null to disable)
    weight_decay: 0.0001            # L2 weight decay
    dropout_rate: 0.2               # Dropout in classifier
    
    # ---- Training Control ----
    monitor_metric: "classification_loss"  # Early stopping metric
    
    # ---- Advanced Features ----
    use_contrastive: false          # Enable contrastive loss
    contrastive_weight: 0.0         # Contrastive loss weight
    xla_flags: null                 # XLA_FLAGS override

# ============================================================================
# CONFIGURATION EXAMPLES
# ============================================================================

# # Quick Test (Dense, Small Dataset)
# data:
#   num_samples: 1000
#   num_labeled: 30
#   epochs: 20
# model:
#   encoder_type: "dense"
#   decoder_type: "dense"
#   latent_dim: 2
#   hidden_dims: [128, 64]
#   max_epochs: 20
#   batch_size: 256

# # Convolutional MNIST (BCE Loss)
# data:
#   num_samples: 50000
#   num_labeled: 500
#   epochs: 50
# model:
#   encoder_type: "conv"
#   decoder_type: "conv"
#   latent_dim: 2
#   reconstruction_loss: "bce"
#   recon_weight: 1.0
#   max_epochs: 50
#   batch_size: 512

# # Mixture Prior Experiment (Unsupervised)
# data:
#   num_samples: 50000
#   num_labeled: 0
#   epochs: 300
# model:
#   prior_type: "mixture"
#   num_components: 10
#   kl_c_weight: 1.0
#   latent_dim: 2
#   max_epochs: 300

# # High-Dimensional Latent Space
# model:
#   latent_dim: 10
#   prior_type: "mixture"
#   num_components: 10
#   hidden_dims: [512, 256, 128]

# ============================================================================
# PARAMETER GUIDANCE
# ============================================================================
#
# Reconstruction Loss:
#   - MSE: Continuous pixel values, use recon_weight ~500
#   - BCE: Binary/binarized images, use recon_weight ~1.0
#
# Prior Type:
#   - Standard: Simple Gaussian N(0,I), faster, good baseline
#   - Mixture: GMM prior, better clustering, needs more data
#
# Architecture:
#   - Dense: Flexible, configurable layers, works for any input
#   - Conv: MNIST-specific (28×28), hardcoded layers, more efficient
#
# Semi-supervised:
#   - num_labeled = 0: Fully unsupervised VAE
#   - num_labeled > 0: Semi-supervised SSVAE
#   - Keep num_labeled << num_samples for true semi-supervision
#
# Training:
#   - Increase batch_size for speed (requires more GPU memory)
#   - Set patience = max_epochs to disable early stopping
#   - Use smaller datasets for quick iteration/debugging
#
# GPU Issues:
#   - Reduce batch_size if OOM
#   - Set JAX_PLATFORMS=cpu for CPU execution
#   - Clear cache: rm -rf ~/.cache/jax*
# ============================================================================
